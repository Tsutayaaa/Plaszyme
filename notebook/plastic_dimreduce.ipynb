{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-15T19:56:03.096666Z",
     "start_time": "2025-08-15T19:55:55.916929Z"
    }
   },
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "labeled_dimreduce.py\n",
    "--------------------\n",
    "固定路径 + 可配置的降维可视化脚本（PCA / UMAP / t-SNE），并用“塑料名称”做点标注。\n",
    "\n",
    "要点\n",
    "- 仅做降维与可视化，不做聚类。\n",
    "- 自动按列归一（robust/zscore/minmax/none），可选对非负列 log1p，行向量 L2。\n",
    "- 标注优先使用 LABEL_TEXT_COL 指定的“塑料名称列”；若未指定，则在 CANDIDATE_NAME_COLS 中自动搜索。\n",
    "- 若仍找不到用于标注的列且未设置 ID_COLS，则抛错（不再退回用序号）。\n",
    "\n",
    "依赖\n",
    "- pandas, numpy, scikit-learn, matplotlib\n",
    "- 可选：umap-learn（未安装会自动跳过 UMAP）\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as mpatheffects\n",
    "\n",
    "plt.switch_backend(\"Agg\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# =======================\n",
    "# 配置区（直接修改这里）\n",
    "# =======================\n",
    "INPUT_CSV: str = \"/Users/shulei/PycharmProjects/Plaszyme/test/outputs/t1.csv\"  # 输入 CSV\n",
    "OUTPUT_DIR: str = \"outputs/dimreduce_labeled\"                                   # 输出目录\n",
    "\n",
    "# 元数据/特征列\n",
    "ID_COLS: List[str] = []                 # 仅保留、不参与降维的列，如 [\"PLZ_ID\"]\n",
    "FEATURE_COLS: List[str] = []            # 指定参与降维的特征列；留空则自动选择所有数值列（排除 ID_COLS）\n",
    "\n",
    "# 降维方法\n",
    "METHODS: List[str] = [\"pca\", \"umap\", \"tsne\"]   # 可选：[\"pca\",\"umap\",\"tsne\"]\n",
    "N_COMPONENTS: int = 2                           # 为 2 时会绘制 2D 图\n",
    "RANDOM_STATE: int = 42\n",
    "\n",
    "# 归一化（按列）\n",
    "COL_SCALE: str = \"robust\"           # \"robust\" | \"zscore\" | \"minmax\" | \"none\"\n",
    "LOG1P_NONNEG: bool = False          # 缩放前对全非负列 log1p\n",
    "APPLY_ROW_L2: bool = False          # 缩放后对每个样本向量 L2 归一\n",
    "\n",
    "# UMAP 参数\n",
    "UMAP_N_NEIGHBORS: int = 15\n",
    "UMAP_MIN_DIST: float = 0.1\n",
    "UMAP_METRIC: str = \"euclidean\"\n",
    "\n",
    "# t-SNE 参数（会基于样本量自动调整 perplexity）\n",
    "TSNE_PERPLEXITY: float = 30.0\n",
    "TSNE_LEARNING_RATE = \"auto\"\n",
    "\n",
    "# —— 图上“塑料名称”标注 ——\n",
    "# 明确指定名称列（强烈推荐）：如 \"plastic\" 或 \"name\"\n",
    "LABEL_TEXT_COL: Optional[str] = \"plastic\"\n",
    "# 若上面为空或该列不存在，将在以下候选里自动寻找（忽略大小写）：\n",
    "CANDIDATE_NAME_COLS: List[str] = [\"plastic\", \"plastic_name\", \"name\", \"polymer\", \"material\"]\n",
    "\n",
    "MAX_LABEL_LEN: int = 28             # 文本过长截断\n",
    "LABEL_OFFSET: float = 0.012         # 文本相对偏移比例\n",
    "DRAW_GUIDE_LINE: bool = True        # 画引线\n",
    "\n",
    "FIGSIZE = (7.0, 5.8)\n",
    "DPI = 180\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 工具函数\n",
    "# =======================\n",
    "def ensure_outdir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_and_split(csv_path: str,\n",
    "                   id_cols: List[str],\n",
    "                   feature_cols: Optional[List[str]] = None\n",
    "                   ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    id_cols = [c for c in id_cols if c in df.columns]\n",
    "\n",
    "    if feature_cols:\n",
    "        feats = [c for c in feature_cols if c in df.columns]\n",
    "        X = df[feats].select_dtypes(include=[np.number]).copy()\n",
    "    else:\n",
    "        feats = [c for c in df.select_dtypes(include=[np.number]).columns if c not in id_cols]\n",
    "        X = df[feats].copy()\n",
    "\n",
    "    if X.shape[1] == 0:\n",
    "        raise ValueError(\"未找到可用的数值特征列，请在 FEATURE_COLS 中显式指定。\")\n",
    "\n",
    "    meta = df[id_cols].copy() if id_cols else pd.DataFrame(index=df.index)\n",
    "    return df, meta, X\n",
    "\n",
    "\n",
    "def preprocess_columns(X: pd.DataFrame,\n",
    "                       col_scale: str = \"robust\",\n",
    "                       log1p_nonneg: bool = False,\n",
    "                       apply_row_l2: bool = False,\n",
    "                       eps: float = 1e-12) -> pd.DataFrame:\n",
    "    X_imp = pd.DataFrame(SimpleImputer(strategy=\"median\").fit_transform(X),\n",
    "                         columns=X.columns, index=X.index)\n",
    "\n",
    "    if log1p_nonneg:\n",
    "        nonneg_cols = [c for c in X_imp.columns if (X_imp[c] >= 0).all()]\n",
    "        if nonneg_cols:\n",
    "            X_imp[nonneg_cols] = np.log1p(X_imp[nonneg_cols])\n",
    "\n",
    "    if col_scale == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_imp),\n",
    "                                columns=X_imp.columns, index=X_imp.index)\n",
    "    elif col_scale == \"zscore\":\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_imp),\n",
    "                                columns=X_imp.columns, index=X_imp.index)\n",
    "    elif col_scale == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_imp),\n",
    "                                columns=X_imp.columns, index=X_imp.index)\n",
    "    elif col_scale == \"none\":\n",
    "        X_scaled = X_imp.copy()\n",
    "    else:\n",
    "        raise ValueError(\"COL_SCALE 仅支持 'robust' | 'zscore' | 'minmax' | 'none'\")\n",
    "\n",
    "    if apply_row_l2:\n",
    "        arr = X_scaled.values\n",
    "        norms = np.sqrt((arr ** 2).sum(axis=1, keepdims=True))\n",
    "        norms = np.maximum(norms, eps)\n",
    "        X_scaled = pd.DataFrame(arr / norms, columns=X_scaled.columns, index=X_scaled.index)\n",
    "\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "def pick_label_series(df: pd.DataFrame,\n",
    "                      id_cols: List[str],\n",
    "                      label_col: Optional[str],\n",
    "                      candidates: List[str],\n",
    "                      max_len: int) -> pd.Series:\n",
    "    # 1) 明确指定\n",
    "    if label_col and (label_col in df.columns):\n",
    "        s = df[label_col].astype(str)\n",
    "    else:\n",
    "        # 2) 候选自动搜索（忽略大小写）\n",
    "        lower_map = {c.lower(): c for c in df.columns}\n",
    "        hit = None\n",
    "        for k in candidates:\n",
    "            if k.lower() in lower_map:\n",
    "                hit = lower_map[k.lower()]\n",
    "                break\n",
    "        # 3) 再做一次宽松匹配（包含关键字）\n",
    "        if not hit:\n",
    "            for c in df.columns:\n",
    "                lc = c.lower()\n",
    "                if any(key in lc for key in [\"plastic\", \"polymer\", \"material\", \"name\"]):\n",
    "                    hit = c\n",
    "                    break\n",
    "\n",
    "        if hit:\n",
    "            s = df[hit].astype(str)\n",
    "        elif id_cols:\n",
    "            # 4) 回退到 ID_COLS 拼接（不使用序号）\n",
    "            parts = [df[c].astype(str) for c in id_cols if c in df.columns]\n",
    "            if parts:\n",
    "                s = pd.Series([\"|\".join(vals) for vals in zip(*parts)], index=df.index)\n",
    "            else:\n",
    "                raise ValueError(\"未找到用于标注的列，请设置 LABEL_TEXT_COL 或在 CANDIDATE_NAME_COLS 中加入正确列名。\")\n",
    "        else:\n",
    "            raise ValueError(\"未找到用于标注的列，请设置 LABEL_TEXT_COL 或在 CANDIDATE_NAME_COLS 中加入正确列名。\")\n",
    "\n",
    "    s = s.fillna(\"\").apply(lambda t: (t if len(t) <= max_len else (t[:max_len - 1] + \"…\")))\n",
    "    return s\n",
    "\n",
    "\n",
    "def save_embedding_csv(meta: pd.DataFrame, emb: np.ndarray, method: str, outdir: str) -> pd.DataFrame:\n",
    "    cols = [f\"{method}_{i+1}\" for i in range(emb.shape[1])]\n",
    "    emb_df = pd.DataFrame(emb, columns=cols, index=meta.index)\n",
    "    out = pd.concat([meta.reset_index(drop=True), emb_df.reset_index(drop=True)], axis=1)\n",
    "    out_path = os.path.join(outdir, f\"{method}_embedding.csv\")\n",
    "    out.to_csv(out_path, index=False)\n",
    "    print(f\"[SAVE] {out_path}\")\n",
    "    return emb_df\n",
    "\n",
    "\n",
    "def scatter2d_labeled(emb: np.ndarray,\n",
    "                      labels: pd.Series,\n",
    "                      title: str,\n",
    "                      xlabel: str,\n",
    "                      ylabel: str,\n",
    "                      out_png: str,\n",
    "                      offset_ratio: float = 0.01,\n",
    "                      draw_guide_line: bool = True):\n",
    "    if emb.shape[1] != 2:\n",
    "        return\n",
    "    x = emb[:, 0]\n",
    "    y = emb[:, 1]\n",
    "    xr = (x.max() - x.min()) or 1.0\n",
    "    yr = (y.max() - y.min()) or 1.0\n",
    "    dx = xr * offset_ratio\n",
    "    dy = yr * offset_ratio\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE, dpi=DPI)\n",
    "    plt.scatter(x, y, s=20, alpha=0.9)\n",
    "\n",
    "    # 白描边提升可读性\n",
    "    text_effect = [mpatheffects.withStroke(linewidth=2.4, foreground=\"white\", alpha=0.9)]\n",
    "    # 扇形微偏移，减少重叠\n",
    "    angles = np.linspace(0, 2 * np.pi, num=len(labels), endpoint=False)\n",
    "    for i, txt in enumerate(labels.values):\n",
    "        ox = dx * np.cos(angles[i])\n",
    "        oy = dy * np.sin(angles[i])\n",
    "        tx, ty = x[i] + ox, y[i] + oy\n",
    "        plt.text(tx, ty, str(txt), fontsize=8, ha=\"left\", va=\"bottom\", path_effects=text_effect)\n",
    "        if draw_guide_line:\n",
    "            plt.plot([x[i], tx], [y[i], ty], linewidth=0.7, alpha=0.6)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "    print(f\"[PLOT] {out_png}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 降维实现\n",
    "# =======================\n",
    "def run_pca(X: np.ndarray, n_components: int, random_state: int):\n",
    "    model = PCA(n_components=n_components, random_state=random_state)\n",
    "    emb = model.fit_transform(X)\n",
    "    var = getattr(model, \"explained_variance_ratio_\", None)\n",
    "    return emb, var\n",
    "\n",
    "\n",
    "def run_umap(X: np.ndarray, n_components: int, random_state: int,\n",
    "             n_neighbors: int, min_dist: float, metric: str):\n",
    "    try:\n",
    "        import umap\n",
    "        UMAP = umap.UMAP\n",
    "    except Exception:\n",
    "        try:\n",
    "            from umap.umap_ import UMAP\n",
    "        except Exception:\n",
    "            print(\"[WARN] 未安装 umap-learn，跳过 UMAP。 (pip install umap-learn)\")\n",
    "            return None\n",
    "    model = UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return model.fit_transform(X)\n",
    "\n",
    "\n",
    "def run_tsne(X: np.ndarray, n_components: int, random_state: int,\n",
    "             perplexity: float, learning_rate):\n",
    "    n = X.shape[0]\n",
    "    if n <= 3 * perplexity:\n",
    "        new_perp = max(3.0, min(perplexity, max(2.0, (n - 1) / 3.2)))\n",
    "        print(f\"[INFO] 样本数较少（n={n}），t-SNE perplexity 自动调整为 {new_perp:.1f}\")\n",
    "        perplexity = new_perp\n",
    "    try:\n",
    "        model = TSNE(\n",
    "            n_components=n_components,\n",
    "            perplexity=perplexity,\n",
    "            learning_rate=learning_rate,\n",
    "            init=\"pca\",\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return model.fit_transform(X)\n",
    "    except TypeError:\n",
    "        model = TSNE(\n",
    "            n_components=n_components,\n",
    "            perplexity=perplexity,\n",
    "            learning_rate=200.0,\n",
    "            init=\"pca\",\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return model.fit_transform(X)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 主流程\n",
    "# =======================\n",
    "def main():\n",
    "    ensure_outdir(OUTPUT_DIR)\n",
    "\n",
    "    df, meta, X = load_and_split(INPUT_CSV, ID_COLS, FEATURE_COLS)\n",
    "    Xn = preprocess_columns(X, COL_SCALE, LOG1P_NONNEG, APPLY_ROW_L2)\n",
    "\n",
    "    labels = pick_label_series(\n",
    "        df=df,\n",
    "        id_cols=ID_COLS,\n",
    "        label_col=LABEL_TEXT_COL,\n",
    "        candidates=CANDIDATE_NAME_COLS,\n",
    "        max_len=MAX_LABEL_LEN\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] 样本数: {Xn.shape[0]} | 特征维度: {Xn.shape[1]} | 方法: {METHODS} | 列缩放: {COL_SCALE}\")\n",
    "\n",
    "    emb_parts: List[pd.DataFrame] = []\n",
    "\n",
    "    # PCA\n",
    "    if \"pca\" in METHODS:\n",
    "        pca_emb, var = run_pca(Xn.values, N_COMPONENTS, RANDOM_STATE)\n",
    "        pca_df = save_embedding_csv(meta, pca_emb, \"pca\", OUTPUT_DIR)\n",
    "        emb_parts.append(pca_df.add_prefix(\"pca_\"))\n",
    "        if var is not None:\n",
    "            var_df = pd.DataFrame({\"PC\": [f\"PC{i+1}\" for i in range(len(var))],\n",
    "                                   \"explained_variance_ratio\": var})\n",
    "            var_df.to_csv(os.path.join(OUTPUT_DIR, \"pca_variance.csv\"), index=False)\n",
    "            print(f\"[SAVE] {os.path.join(OUTPUT_DIR, 'pca_variance.csv')}\")\n",
    "        if N_COMPONENTS == 2:\n",
    "            scatter2d_labeled(pca_emb, labels, \"PCA (2D)\", \"PC1\", \"PC2\",\n",
    "                              os.path.join(OUTPUT_DIR, \"pca_2d_labeled.png\"),\n",
    "                              offset_ratio=LABEL_OFFSET, draw_guide_line=DRAW_GUIDE_LINE)\n",
    "\n",
    "    # UMAP\n",
    "    if \"umap\" in METHODS:\n",
    "        umap_emb = run_umap(Xn.values, N_COMPONENTS, RANDOM_STATE,\n",
    "                            UMAP_N_NEIGHBORS, UMAP_MIN_DIST, UMAP_METRIC)\n",
    "        if umap_emb is not None:\n",
    "            umap_df = save_embedding_csv(meta, umap_emb, \"umap\", OUTPUT_DIR)\n",
    "            emb_parts.append(umap_df.add_prefix(\"umap_\"))\n",
    "            if N_COMPONENTS == 2:\n",
    "                scatter2d_labeled(umap_emb, labels, \"UMAP (2D)\", \"UMAP-1\", \"UMAP-2\",\n",
    "                                  os.path.join(OUTPUT_DIR, \"umap_2d_labeled.png\"),\n",
    "                                  offset_ratio=LABEL_OFFSET, draw_guide_line=DRAW_GUIDE_LINE)\n",
    "\n",
    "    # t-SNE\n",
    "    if \"tsne\" in METHODS:\n",
    "        tsne_emb = run_tsne(Xn.values, N_COMPONENTS, RANDOM_STATE,\n",
    "                            TSNE_PERPLEXITY, TSNE_LEARNING_RATE)\n",
    "        tsne_df = save_embedding_csv(meta, tsne_emb, \"tsne\", OUTPUT_DIR)\n",
    "        emb_parts.append(tsne_df.add_prefix(\"tsne_\"))\n",
    "        if N_COMPONENTS == 2:\n",
    "            scatter2d_labeled(tsne_emb, labels, \"t-SNE (2D)\", \"tSNE-1\", \"tSNE-2\",\n",
    "                              os.path.join(OUTPUT_DIR, \"tsne_2d_labeled.png\"),\n",
    "                              offset_ratio=LABEL_OFFSET, draw_guide_line=DRAW_GUIDE_LINE)\n",
    "\n",
    "    # 合并嵌入\n",
    "    if emb_parts:\n",
    "        merged = pd.concat([meta.reset_index(drop=True)] + emb_parts, axis=1)\n",
    "        merged.to_csv(os.path.join(OUTPUT_DIR, \"all_embeddings_merged.csv\"), index=False)\n",
    "        print(f\"[SAVE] {os.path.join(OUTPUT_DIR, 'all_embeddings_merged.csv')}\")\n",
    "\n",
    "    print(\"[DONE] 降维 + 塑料名称标注 完成。输出位于：\", os.path.abspath(OUTPUT_DIR))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 样本数: 17 | 特征维度: 27 | 方法: ['pca', 'umap', 'tsne'] | 列缩放: robust\n",
      "[SAVE] outputs/dimreduce_labeled/pca_embedding.csv\n",
      "[SAVE] outputs/dimreduce_labeled/pca_variance.csv\n",
      "[PLOT] outputs/dimreduce_labeled/pca_2d_labeled.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Plaszyme/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] outputs/dimreduce_labeled/umap_embedding.csv\n",
      "[PLOT] outputs/dimreduce_labeled/umap_2d_labeled.png\n",
      "[INFO] 样本数较少（n=17），t-SNE perplexity 自动调整为 5.0\n",
      "[SAVE] outputs/dimreduce_labeled/tsne_embedding.csv\n",
      "[PLOT] outputs/dimreduce_labeled/tsne_2d_labeled.png\n",
      "[SAVE] outputs/dimreduce_labeled/all_embeddings_merged.csv\n",
      "[DONE] 降维 + 塑料名称标注 完成。输出位于： /Users/shulei/PycharmProjects/Plaszyme/notebook/outputs/dimreduce_labeled\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
